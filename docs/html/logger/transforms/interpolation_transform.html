<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1">
<meta name="generator" content="pdoc3 0.11.6">
<title>logger.transforms.interpolation_transform API documentation</title>
<meta name="description" content="Compute interpolations of input data.">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/sanitize.min.css" integrity="sha512-y1dtMcuvtTMJc1yPgEqF0ZjQbhnc/bFhyvIyVNb9Zk5mIGtqVaAB1Ttl28su8AvFMOY0EwRbAe+HCLqj6W7/KA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/typography.min.css" integrity="sha512-Y1DYSb995BAfxobCkKepB1BqJJTPrOp3zPL74AWFugHHmmdcvO+C48WLrUOlhGMc0QG7AE3f7gmvvcrmX2fDoA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:1.5em;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:2em 0 .50em 0}h3{font-size:1.4em;margin:1.6em 0 .7em 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .2s ease-in-out}a:visited{color:#503}a:hover{color:#b62}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900;font-weight:bold}pre code{font-size:.8em;line-height:1.4em;padding:1em;display:block}code{background:#f3f3f3;font-family:"DejaVu Sans Mono",monospace;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source > summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible;min-width:max-content}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em 1em;margin:1em 0}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul ul{padding-left:1em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js" integrity="sha512-D9gUyxqja7hBtkWpPWGt9wfbfaMGVt9gnyCvYa+jojwwPHLCzUm5i8rpk7vD7wNee9bA35eYIjobYPaQuKS1MQ==" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => {
hljs.configure({languages: ['bash', 'css', 'diff', 'graphql', 'ini', 'javascript', 'json', 'plaintext', 'python', 'python-repl', 'rust', 'shell', 'sql', 'typescript', 'xml', 'yaml']});
hljs.highlightAll();
/* Collapse source docstrings */
setTimeout(() => {
[...document.querySelectorAll('.hljs.language-python > .hljs-string')]
.filter(el => el.innerHTML.length > 200 && ['"""', "'''"].includes(el.innerHTML.substring(0, 3)))
.forEach(el => {
let d = document.createElement('details');
d.classList.add('hljs-string');
d.innerHTML = '<summary>"""</summary>' + el.innerHTML.substring(3);
el.replaceWith(d);
});
}, 100);
})</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>logger.transforms.interpolation_transform</code></h1>
</header>
<section id="section-intro">
<p>Compute interpolations of input data.</p>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="logger.transforms.interpolation_transform.interpolate"><code class="name flex">
<span>def <span class="ident">interpolate</span></span>(<span>algorithm, values, timestamp, now)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def interpolate(algorithm, values, timestamp, now):
    &#34;&#34;&#34;An omnibus routine for taking a list of timestamped values, a
    specification of an averaging algorithm, and returning a value
    computed at the specified timestamp. Returns None if there aren&#39;t
    enough data to compute a value.

    algorithm    The name of the algorithm to be used

    values       A list of [(timestamp, value),...] pairs

    timestamp    The timestamp for which interpolation should be computed

    now          Timestamp now. This should be used to determine whether
                 we&#39;re far enough beyond our timestamp to compute a value.
    &#34;&#34;&#34;
    if not type(algorithm) is dict:
        logging.warning(&#39;Function interpolate() handed non-dict algorithm &#39;
                        &#39;specification: %s&#39;, algorithm)
        return None
    if not values:
        logging.debug(&#39;Function interpolate() handed empty values list&#39;)
        return None

    ##################
    # Select algorithm
    alg_type = algorithm.get(&#39;type&#39;)

    # boxcar_average: all values within symmetric interval window get
    # same weight.
    if alg_type == &#39;boxcar_average&#39;:
        window = algorithm.get(&#39;window&#39;, 10)  # How far back/forward to average
        lower_limit = timestamp - window / 2
        upper_limit = timestamp + window / 2
        vals_to_average = [val for ts, val in values
                           if ts &gt;= lower_limit and ts &lt;= upper_limit]
        if not vals_to_average:
            return None

        try:
            return mean(vals_to_average)
        except TypeError:
            logging.error(&#39;Non-numeric value in interpolation list: %s&#39;, vals_to_average)
            return None

    # nearest: return value of nearest timestamp. Note that we assume
    # timestamps are in order, so once distance starts going up, we&#39;re
    # done.
    if alg_type == &#39;nearest&#39;:
        best_distance = float(&#39;inf&#39;)
        value = None
        for i in range(len(values)):
            ts, ts_value = values[i]
            distance = abs(ts - timestamp)
            if distance &lt;= best_distance:
                best_distance = distance
                value = ts_value
            else:
                break
        return value

    # polar_average: interpret as an angle in degrees. Convert to points
    # on a unit circle and return the angle of their centroid from the origin.
    if alg_type == &#39;polar_average&#39;:
        window = algorithm.get(&#39;window&#39;, 10)  # How far back/forward to average
        lower_limit = timestamp - window / 2
        upper_limit = timestamp + window / 2
        vals_to_average = [val for ts, val in values
                           if ts &gt;= lower_limit and ts &lt;= upper_limit]
        if not vals_to_average:
            return None

        try:
            val_radians = [radians(val) for val in vals_to_average]
            x_mean = mean([sin(val) for val in val_radians])
            y_mean = mean([cos(val) for val in val_radians])
            angle = degrees(atan2(x_mean, y_mean))
            if angle &lt; 0:
                angle += 360
            return angle
        except TypeError:
            logging.error(&#39;Non-numeric value in interpolation list: %s&#39;, vals_to_average)
            return None

    # Not an algorithm we recognize
    else:
        logging.warning(&#39;Function interpolate() received unrecognized algorithm &#39;
                        &#39;type: %s&#39;, alg_type)
        return None</code></pre>
</details>
<div class="desc"><p>An omnibus routine for taking a list of timestamped values, a
specification of an averaging algorithm, and returning a value
computed at the specified timestamp. Returns None if there aren't
enough data to compute a value.</p>
<p>algorithm
The name of the algorithm to be used</p>
<p>values
A list of [(timestamp, value),&hellip;] pairs</p>
<p>timestamp
The timestamp for which interpolation should be computed</p>
<p>now
Timestamp now. This should be used to determine whether
we're far enough beyond our timestamp to compute a value.</p></div>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="logger.transforms.interpolation_transform.InterpolationTransform"><code class="flex name class">
<span>class <span class="ident">InterpolationTransform</span></span>
<span>(</span><span>field_spec, interval, window, data_id=None, metadata_interval=None)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class InterpolationTransform(DerivedDataTransform):
    &#34;&#34;&#34;Transform that computes interpolations of the specified variables.
    &#34;&#34;&#34;

    def __init__(self, field_spec, interval, window, data_id=None, metadata_interval=None):
        &#34;&#34;&#34;
        ```
        field_spec - a dict of interpolated variables that are to be created,
                where the key is the new variable&#39;s name, and the value is a dict
                specifying the source field name and the algorithm that is to be
                used to do the interpolation. E.g.:

               {
                 &#39;AvgCNAVCourseTrue&#39;: {
                   &#39;source&#39;: &#39;CNAVCourseTrue&#39;,
                   &#39;algorithm&#39;: {
                     &#39;type&#39;: &#39;boxcar_average&#39;,
                     &#39;window&#39;: 30
                   },
                 },
                 &#39;AvgCNAVGPSDay&#39;: {
                   &#39;source&#39;: &#39;CNAVGPSDay&#39;,
                   &#39;algorithm&#39;: { &#39;type&#39;: &#39;nearest&#39; },
                 },
                 ...
               }

               To simplify templating, can also accept a spec of the form
               of a list:

               [
                 { sources: [MwxAirTemp, RTMPTemp, ...],
                   algorithm: boxcar_average,
                   window: 10,
                   result_prefix: Avg
                 },
                 { sources: [PortTrueWindDir, StbdTrueWindDir],
                   algorithm: polar_average,
                   window: 10,
                   result_prefix: Avg
                 }
               ]

        interval - At what intervals (in seconds) should the interpolation
               be computed?

        window - Time window (in seconds) of data we should maintain
               around the computation we&#39;re going to make.

        data_id - What data id to assign to the output

        metadata_interval - how many seconds between when we attach field metadata
               to a record we send out.
        ```

        &#34;&#34;&#34;
        self.field_spec = {}
        self.source_fields = set()
        if isinstance(field_spec, dict):
            for result_field, entry in field_spec.items():
                if &#39;source&#39; in entry and &#39;algorithm&#39; in entry:
                    self.field_spec[result_field] = entry
                    self.source_fields.add(entry.get(&#39;source&#39;))
                else:
                    logging.warning(&#39;InterpolationTransform field definition for %s &#39;
                                    &#39;must specify both &#34;source&#34; and &#34;algorithm&#34;: %s&#39;,
                                    result_field, entry)

        # Alternate way of setting up a field spec that makes it easier to templatize.
        # We&#39;ll expand the list of specs into a traditional field_spec
        elif isinstance(field_spec, list):
            for spec_instance in field_spec:
                # Each spec_instance should be a dict of fields:, algorithm:,
                # output_field_prefix: and window:
                if not isinstance(spec_instance, dict):
                    raise ValueError(&#39;InterpolationTransform: if field_spec is list, must be &#39;
                                     f&#39;a list of dicts; found list of {type(spec_instance)}&#39;)
                sources = spec_instance.get(&#39;sources&#39;)

                if not isinstance(sources, list):
                    raise ValueError(&#39;InterpolationTransform: sources for field spec must be &#39;
                                     f&#39;a list ; found {type(spec_instance)}&#39;)

                # Expand source list into a traditional field_spec
                algorithm = spec_instance.get(&#39;algorithm&#39;)
                window = spec_instance.get(&#39;window&#39;)
                result_prefix = spec_instance.get(&#39;result_prefix&#39;)
                for source in sources:
                    entry = {&#39;source&#39;: source, &#39;algorithm&#39;: {&#39;type&#39;: algorithm, &#39;window&#39;: window}}
                    result_field = result_prefix + source
                    self.field_spec[result_field] = entry

                # Finally, stash sources so we know what to look for
                self.source_fields.update(sources)

        else:
            raise ValueError(&#39;InterpolationTransform: field_spec must be either list &#39;
                             f&#39;or dict. Found {type(field_spec)}&#39;)

        self.interval = interval
        self.window = window
        self.data_id = data_id
        self.metadata_interval = metadata_interval

        # A dict of the cached values we&#39;re hanging onto - use sorted
        # lists of (timestamp, value) pairs
        self.cached_values = {f: [] for f in self.source_fields}

        # The next timestamp we&#39;d like to emit. Is set the first time we
        # call transform().
        self.next_timestamp = 0
        self.earliest_timestamp = float(&#39;inf&#39;)  # Track earliest timestamp we&#39;ve seen
        self.latest_timestamp = 0
        self.last_metadata_send = 0  # last time we&#39;ve sent metadata

    ############################
    def fields(self):
        &#34;&#34;&#34;Which fields are we interested in to produce transformed data?&#34;&#34;&#34;
        return list(self.source_fields)

    ############################
    def _metadata(self):
        &#34;&#34;&#34;Return a dict of metadata for our derived fields.&#34;&#34;&#34;
        metadata_fields = {
            &#39;field&#39;: {
                &#39;description&#39;:
                    &#39;Interpolated values of %s via %s&#39; %
                    (entry[&#39;source&#39;], entry[&#39;algorithm&#39;]),
                &#39;device&#39;: &#39;InterpolationTransform&#39;,
                &#39;device_type&#39;: &#39;DerivedDataTransform&#39;,
                &#39;device_type_field&#39;: result_field
            }
            for result_field, entry in self.field_spec.items()
        }
        return metadata_fields

    ############################
    def _add_record(self, record):
        &#34;&#34;&#34;Cached the values contained in a new record, maintaining timestamp order.&#34;&#34;&#34;
        if type(record) not in [DASRecord, dict]:
            logging.error(&#39;InterpolationTransform records must be dict or &#39;
                          &#39;DASRecord. Received type %s: %s&#39;, type(record), record)
            return 0

        if type(record) is DASRecord:
            timestamp = record.timestamp
            fields = record.fields
        else:
            timestamp = record.get(&#39;timestamp&#39;, 0)
            fields = record.get(&#39;fields&#39;)

        if not fields:
            logging.info(&#39;InterpolationTransform: record has no fields: %s&#39;, record)
            return timestamp

        # First, copy the new data into our cache.  NOTE: It&#39;s a judgment
        # call whether it&#39;s more efficient to iterate over the fields
        # we&#39;re looking for or the fields in the record.
        for field, new_value in fields.items():
            if field not in self.source_fields:
                continue

            # Examine the value we&#39;ve gotten. If list, we assume it&#39;s [(ts,
            # value), (ts, value),...]
            if type(new_value) is list:
                for ts, val in new_value.items():
                    self._insert_sorted(field, ts, val)
                    logging.debug(f&#39;adding {ts}: {field} - {val}&#39;)

            # If not list, assume DASRecord or simple field dict; add tuple
            elif timestamp:
                self._insert_sorted(field, timestamp, new_value)
                logging.debug(f&#39;adding {timestamp}: {field} - {new_value}&#39;)
            else:
                logging.warning(&#39;Interpolation found no timestamp in &#39;
                                &#39;record: %s&#39;, record)

        # Update our tracking of the earliest and latest timestamps we&#39;ve seen
        self.earliest_timestamp = min(self.earliest_timestamp, timestamp)
        self.latest_timestamp = max(self.latest_timestamp, timestamp)

        # Return the timestamp of the record
        return timestamp

    ############################
    def _insert_sorted(self, field: str, timestamp: float, value: Any) -&gt; None:
        &#34;&#34;&#34;Insert a (timestamp, value) pair into the sorted cached values for a field.&#34;&#34;&#34;
        cache = self.cached_values[field]

        # Use binary search to find insertion position to maintain sorted order
        timestamps = [ts for ts, _ in cache]
        pos = bisect.bisect_left(timestamps, timestamp)

        # Insert at correct position to maintain sort order
        cache.insert(pos, (timestamp, value))

    ############################
    def _clean_cache(self):
        &#34;&#34;&#34;Remove values from cache that are too old to be useful.&#34;&#34;&#34;
        for field in self.source_fields:
            # Iterate forward through field cache until we find a timestamp
            # that is recent enough to keep
            cache = self.cached_values[field]
            lower_limit = self.next_timestamp - self.window / 2
            keep_index = 0
            while keep_index &lt; len(cache) and cache[keep_index][0] &lt; lower_limit:
                keep_index += 1

            # Throw away everything before that index
            self.cached_values[field] = cache[keep_index:]

    ############################
    def transform(self, record: Union[DASRecord, dict]):
        &#34;&#34;&#34;Incorporate any useable fields in this record, and if it gives
        us any new interpolated values, aggregate and return them as a list of
        dicts of the form:

        [
          {&#39;timestamp&#39;: timestamp,
           &#39;fields&#39;: {
             fieldname: value,
             fieldname: value,
             ...
            }
          },
          {&#39;timestamp&#39;: timestamp,
           &#39;fields&#39;: ...
          }
        ]

        If there are insufficient data in the window to compute any
        interpolation, return an empty list.
        &#34;&#34;&#34;
        # See if it&#39;s something we can process, and if not, try digesting
        if not self.can_process_record(record):  # inherited from Transform()
            return self.digest_record(record)  # inherited from Transform()

        # Add the record and remember its timestamp.
        record_timestamp = self._add_record(record)

        # First time through, our &#39;next_timestamp&#39; will be zero. Set it to
        # a good starting place.
        if not self.next_timestamp:
            self.next_timestamp = self.earliest_timestamp

        # What fields do we have data for in our cache?
        non_empty = {}
        for dest, spec in self.field_spec.items():
            source = spec.get(&#39;source&#39;)
            if source:
                values = self.cached_values.get(source, [])
                if len(values):
                    non_empty[dest] = [source, len(values)]

        # Iterate through all timestamps up to the edge of what we can fit
        # in our window without running into the edge of our latest timestamp.
        results = []
        logging.debug(f&#39;latest timestamp: {self.latest_timestamp}, next: {self.next_timestamp}&#39;)
        while self.next_timestamp &lt; self.latest_timestamp - self.window / 2:
            # Clean out old data
            self._clean_cache()

            result = {}
            for result_field, entry in self.field_spec.items():
                source = entry.get(&#39;source&#39;)
                source_values = self.cached_values.get(source)
                algorithm = entry.get(&#39;algorithm&#39;)
                # logging.warning(&#39;%s-&gt;%s: %d values&#39;,
                #                source, result_field, len(source_values))
                value = interpolate(algorithm, source_values,
                                    self.next_timestamp,
                                    self.latest_timestamp)
                if value is not None:
                    result[result_field] = value
            if result:
                result_record = {&#39;timestamp&#39;: self.next_timestamp, &#39;fields&#39;: result}
                if self.data_id:
                    result_record[&#39;data_id&#39;] = self.data_id
                results.append(result_record)
            self.next_timestamp += self.interval

        return results</code></pre>
</details>
<div class="desc"><p>Transform that computes interpolations of the specified variables.</p>
<pre><code>field_spec - a dict of interpolated variables that are to be created,
        where the key is the new variable's name, and the value is a dict
        specifying the source field name and the algorithm that is to be
        used to do the interpolation. E.g.:

       {
         'AvgCNAVCourseTrue': {
           'source': 'CNAVCourseTrue',
           'algorithm': {
             'type': 'boxcar_average',
             'window': 30
           },
         },
         'AvgCNAVGPSDay': {
           'source': 'CNAVGPSDay',
           'algorithm': { 'type': 'nearest' },
         },
         ...
       }

       To simplify templating, can also accept a spec of the form
       of a list:

       [
         { sources: [MwxAirTemp, RTMPTemp, ...],
           algorithm: boxcar_average,
           window: 10,
           result_prefix: Avg
         },
         { sources: [PortTrueWindDir, StbdTrueWindDir],
           algorithm: polar_average,
           window: 10,
           result_prefix: Avg
         }
       ]

interval - At what intervals (in seconds) should the interpolation
       be computed?

window - Time window (in seconds) of data we should maintain
       around the computation we're going to make.

data_id - What data id to assign to the output

metadata_interval - how many seconds between when we attach field metadata
       to a record we send out.
</code></pre></div>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="logger.transforms.derived_data_transform.DerivedDataTransform" href="derived_data_transform.html#logger.transforms.derived_data_transform.DerivedDataTransform">DerivedDataTransform</a></li>
<li><a title="logger.transforms.transform.Transform" href="transform.html#logger.transforms.transform.Transform">Transform</a></li>
<li><a title="logger.utils.base_module.BaseModule" href="../utils/base_module.html#logger.utils.base_module.BaseModule">BaseModule</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="logger.transforms.interpolation_transform.InterpolationTransform.fields"><code class="name flex">
<span>def <span class="ident">fields</span></span>(<span>self)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fields(self):
    &#34;&#34;&#34;Which fields are we interested in to produce transformed data?&#34;&#34;&#34;
    return list(self.source_fields)</code></pre>
</details>
<div class="desc"><p>Which fields are we interested in to produce transformed data?</p></div>
</dd>
<dt id="logger.transforms.interpolation_transform.InterpolationTransform.transform"><code class="name flex">
<span>def <span class="ident">transform</span></span>(<span>self,<br>record: <a title="logger.utils.das_record.DASRecord" href="../utils/das_record.html#logger.utils.das_record.DASRecord">DASRecord</a> | dict)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def transform(self, record: Union[DASRecord, dict]):
    &#34;&#34;&#34;Incorporate any useable fields in this record, and if it gives
    us any new interpolated values, aggregate and return them as a list of
    dicts of the form:

    [
      {&#39;timestamp&#39;: timestamp,
       &#39;fields&#39;: {
         fieldname: value,
         fieldname: value,
         ...
        }
      },
      {&#39;timestamp&#39;: timestamp,
       &#39;fields&#39;: ...
      }
    ]

    If there are insufficient data in the window to compute any
    interpolation, return an empty list.
    &#34;&#34;&#34;
    # See if it&#39;s something we can process, and if not, try digesting
    if not self.can_process_record(record):  # inherited from Transform()
        return self.digest_record(record)  # inherited from Transform()

    # Add the record and remember its timestamp.
    record_timestamp = self._add_record(record)

    # First time through, our &#39;next_timestamp&#39; will be zero. Set it to
    # a good starting place.
    if not self.next_timestamp:
        self.next_timestamp = self.earliest_timestamp

    # What fields do we have data for in our cache?
    non_empty = {}
    for dest, spec in self.field_spec.items():
        source = spec.get(&#39;source&#39;)
        if source:
            values = self.cached_values.get(source, [])
            if len(values):
                non_empty[dest] = [source, len(values)]

    # Iterate through all timestamps up to the edge of what we can fit
    # in our window without running into the edge of our latest timestamp.
    results = []
    logging.debug(f&#39;latest timestamp: {self.latest_timestamp}, next: {self.next_timestamp}&#39;)
    while self.next_timestamp &lt; self.latest_timestamp - self.window / 2:
        # Clean out old data
        self._clean_cache()

        result = {}
        for result_field, entry in self.field_spec.items():
            source = entry.get(&#39;source&#39;)
            source_values = self.cached_values.get(source)
            algorithm = entry.get(&#39;algorithm&#39;)
            # logging.warning(&#39;%s-&gt;%s: %d values&#39;,
            #                source, result_field, len(source_values))
            value = interpolate(algorithm, source_values,
                                self.next_timestamp,
                                self.latest_timestamp)
            if value is not None:
                result[result_field] = value
        if result:
            result_record = {&#39;timestamp&#39;: self.next_timestamp, &#39;fields&#39;: result}
            if self.data_id:
                result_record[&#39;data_id&#39;] = self.data_id
            results.append(result_record)
        self.next_timestamp += self.interval

    return results</code></pre>
</details>
<div class="desc"><p>Incorporate any useable fields in this record, and if it gives
us any new interpolated values, aggregate and return them as a list of
dicts of the form:</p>
<p>[
{'timestamp': timestamp,
'fields': {
fieldname: value,
fieldname: value,
&hellip;
}
},
{'timestamp': timestamp,
'fields': &hellip;
}
]</p>
<p>If there are insufficient data in the window to compute any
interpolation, return an empty list.</p></div>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="logger.transforms.derived_data_transform.DerivedDataTransform" href="derived_data_transform.html#logger.transforms.derived_data_transform.DerivedDataTransform">DerivedDataTransform</a></b></code>:
<ul class="hlist">
<li><code><a title="logger.transforms.derived_data_transform.DerivedDataTransform.can_process_record" href="../utils/base_module.html#logger.utils.base_module.BaseModule.can_process_record">can_process_record</a></code></li>
<li><code><a title="logger.transforms.derived_data_transform.DerivedDataTransform.digest_record" href="../utils/base_module.html#logger.utils.base_module.BaseModule.digest_record">digest_record</a></code></li>
</ul>
</li>
</ul>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="logger.transforms" href="index.html">logger.transforms</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="logger.transforms.interpolation_transform.interpolate" href="#logger.transforms.interpolation_transform.interpolate">interpolate</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="logger.transforms.interpolation_transform.InterpolationTransform" href="#logger.transforms.interpolation_transform.InterpolationTransform">InterpolationTransform</a></code></h4>
<ul class="">
<li><code><a title="logger.transforms.interpolation_transform.InterpolationTransform.fields" href="#logger.transforms.interpolation_transform.InterpolationTransform.fields">fields</a></code></li>
<li><code><a title="logger.transforms.interpolation_transform.InterpolationTransform.transform" href="#logger.transforms.interpolation_transform.InterpolationTransform.transform">transform</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.11.6</a>.</p>
</footer>
</body>
</html>
