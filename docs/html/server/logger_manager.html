<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>server.logger_manager API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>server.logger_manager</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">#! /usr/bin/env python3
&#34;&#34;&#34;
&#34;&#34;&#34;
import datetime
import getpass  # to get username
import logging
import multiprocessing
import os
import signal
import socket  # to get hostname
import sys
import threading
import time

from importlib import reload
from os.path import dirname, realpath

# Add the openrvdas components onto sys.path
sys.path.append(dirname(dirname(realpath(__file__))))

# Imports for running CachedDataServer
from server.cached_data_server import CachedDataServer  # noqa: E402

from server.logger_supervisor import LoggerSupervisor  # noqa: E402
from server.server_api import ServerAPI  # noqa: E402
from logger.transforms.to_das_record_transform import ToDASRecordTransform  # noqa: E402
from logger.utils.stderr_logging import DEFAULT_LOGGING_FORMAT  # noqa: E402
from logger.utils.stderr_logging import StdErrLoggingHandler  # noqa: E402
from logger.utils.read_config import read_config  # noqa: E402

# For sending stderr to CachedDataServer
from logger.utils.das_record import DASRecord  # noqa: E402
from logger.writers.cached_data_writer import CachedDataWriter  # noqa: E402
from logger.writers.composed_writer import ComposedWriter  # noqa: E402

try:
    from server.sqlite_server_api import SQLiteServerAPI  # noqa: E402
    SQLITE_API_DEFINED = True
except ImportError:
    SQLITE_API_DEFINED = False

DEFAULT_MAX_TRIES = 3

SOURCE_NAME = &#39;LoggerManager&#39;
USER = getpass.getuser()
HOSTNAME = socket.gethostname()

DEFAULT_DATA_SERVER_WEBSOCKET = &#39;localhost:8766&#39;

############################


def kill_handler(self, signum):
    &#34;&#34;&#34;Translate an external signal (such as we&#39;d get from os.kill) into a
    KeyboardInterrupt, which will signal the start() loop to exit nicely.&#34;&#34;&#34;
    raise KeyboardInterrupt(&#39;Received external kill signal&#39;)

################################################################################
################################################################################


class LoggerManager:
    ############################
    def __init__(self,
                 api, supervisor, data_server_websocket=None,
                 stderr_file_pattern=&#39;/var/log/openrvdas/{logger}.stderr&#39;,
                 interval=0.25, log_level=logging.info, logger_log_level=logging.WARNING):
        &#34;&#34;&#34;Read desired/current logger configs from Django DB and try to run the
        loggers specified in those configs.
        ```
        api - ServerAPI (or subclass) instance by which LoggerManager will get
              its data store updates

        supervisor - a LoggerSupervisor object to use to manage logger
              processes.

        data_server_websocket - cached data server host:port to which we are
              going to send our status updates.

        stderr_file_pattern - Pattern into which logger name will be
              interpolated to create the file path/name to which the
              logger&#39;s stderr will be written. E.g.
              &#39;/var/log/openrvdas/{logger}.stderr&#39; If
              data_server_websocket is defined, will write logger
              stderr to it.

        interval - number of seconds to sleep between checking/updating loggers

        log_level - LoggerManager&#39;s log level

        logger_log_level - At what logging level our component loggers
              should operate.
        ```

        &#34;&#34;&#34;
        # Set signal to catch SIGTERM and convert it into a
        # KeyboardInterrupt so we can shut things down gracefully.
        try:
            signal.signal(signal.SIGTERM, kill_handler)
        except ValueError:
            logging.warning(&#39;LoggerManager not running in main thread; &#39;
                            &#39;shutting down with Ctl-C may not work.&#39;)

        # api class must be subclass of ServerAPI
        if not issubclass(type(api), ServerAPI):
            raise ValueError(&#39;Passed api &#34;%s&#34; must be subclass of ServerAPI&#39; % api)
        self.api = api
        self.supervisor = supervisor

        # Data server to which we&#39;re going to send status updates
        if data_server_websocket:
            self.data_server_writer = CachedDataWriter(data_server_websocket)
        else:
            self.data_server_writer = None

        self.stderr_file_pattern = stderr_file_pattern
        self.interval = interval
        self.logger_log_level = logger_log_level

        # Try to set up logging, right off the bat: reset logging to its
        # freshly-imported state and add handler that also sends logged
        # messages to the cached data server.
        reload(logging)
        logging.basicConfig(format=DEFAULT_LOGGING_FORMAT, level=log_level)

        if self.data_server_writer:
            cds_writer = ComposedWriter(
                transforms=ToDASRecordTransform(data_id=&#39;stderr&#39;,
                                                field_name=&#39;stderr:logger_manager&#39;),
                writers=self.data_server_writer)
            logging.getLogger().addHandler(StdErrLoggingHandler(cds_writer))

        # How our various loops and threads will know it&#39;s time to quit
        self.quit_flag = False

        # Where we store the latest cruise definition and status reports.
        self.cruise = None
        self.cruise_filename = None
        self.cruise_loaded_time = 0

        self.loggers = {}
        self.config_to_logger = {}

        self.logger_status = None
        self.status_time = 0

        # We loop to check the logger status and pass it off to the cached
        # data server. Do this in a separate thread.
        self.check_logger_status_thread = None

        # We&#39;ll loop to check the API for updates to our desired
        # configs. Do this in a separate thread. Also keep track of
        # currently active configs so that we know when an update is
        # actually needed.
        self.update_configs_thread = None
        self.config_lock = threading.Lock()

        self.active_mode = None  # which mode is active now?
        self.active_configs = None  # which configs are active now?

    ############################
    def start(self):
        &#34;&#34;&#34;Start the threads that make up the LoggerManager operation:

        1. Configuration update loop
        2. Loop to read logger stderr/status and either output it or
           transmit it to a cached data server

        Start threads as daemons so that they&#39;ll automatically terminate
        if the main thread does.
        &#34;&#34;&#34;
        logging.info(&#39;Starting LoggerManager&#39;)

        # Check logger status in a separate thread. If we&#39;ve got the
        # address of a data server websocket, send our updates to it.
        self.check_logger_status_loop_thread = threading.Thread(
            name=&#39;check_logger_status_loop&#39;,
            target=self._check_logger_status_loop, daemon=True)
        self.check_logger_status_loop_thread.start()

        # Update configs in a separate thread.
        self.update_configs_thread = threading.Thread(
            name=&#39;update_configs_loop&#39;,
            target=self._update_configs_loop, daemon=True)
        self.update_configs_thread.start()

        # Check logger status in a separate thread. If we&#39;ve got the
        # address of a data server websocket, send our updates to it.
        self.send_cruise_definition_loop_thread = threading.Thread(
            name=&#39;send_cruise_definition_loop&#39;,
            target=self._send_cruise_definition_loop, daemon=True)
        self.send_cruise_definition_loop_thread.start()

    ############################
    def quit(self):
        &#34;&#34;&#34;Exit the loop and shut down all loggers.&#34;&#34;&#34;
        self.quit_flag = True

    ############################
    def _load_new_definition_from_api(self):
        &#34;&#34;&#34;Fetch a new cruise definition from API and build local maps. Then
        send anupdated cruise definition to the console.
        &#34;&#34;&#34;
        logging.info(&#39;Fetching new cruise definitions from API&#39;)
        try:
            with self.config_lock:
                self.loggers = self.api.get_loggers()
                self.config_to_logger = {}
                for logger, logger_configs in self.loggers.items():
                    # Map config_name-&gt;logger
                    for config in self.loggers[logger].get(&#39;configs&#39;, []):
                        self.config_to_logger[config] = logger

                # This is a redundant grab of data when we&#39;re called from
                # _send_cruise_definition_loop(), but we may also be called
                # from a callback when the API alerts us that something has
                # changed. So we need to re-grab self.cruise
                self.cruise = self.api.get_configuration()  # a Cruise object
                self.cruise_filename = self.cruise.get(&#39;config_filename&#39;, None)
                loaded_time = self.cruise.get(&#39;loaded_time&#39;)
                self.cruise_loaded_time = datetime.datetime.timestamp(loaded_time)
                self.active_mode = self.api.get_active_mode()

                # Send updated cruise definition to CDS for console to read.
                cruise_dict = {
                    &#39;cruise_id&#39;: self.cruise.get(&#39;id&#39;, &#39;&#39;),
                    &#39;filename&#39;: self.cruise_filename,
                    &#39;config_timestamp&#39;: self.cruise_loaded_time,
                    &#39;loggers&#39;: self.loggers,
                    &#39;modes&#39;: self.cruise.get(&#39;modes&#39;, {}),
                    &#39;active_mode&#39;: self.active_mode,
                }
                logging.info(&#39;Sending updated cruise definitions to CDS.&#39;)
                self._write_record_to_data_server(
                    &#39;status:cruise_definition&#39;, cruise_dict)
        except (AttributeError, ValueError, TypeError) as e:
            logging.info(&#39;Failed to update cruise definition: %s&#39;, e)

    ############################
    def _check_logger_status_loop(self):
        &#34;&#34;&#34;Grab logger status message from supervisor and send to cached data
        server via websocket. Also send cruise mode as separate message.
        &#34;&#34;&#34;
        while not self.quit_flag:
            now = time.time()
            try:
                config_status = self.supervisor.get_status()
                with self.config_lock:
                    # Stash status, note time and send update
                    self.config_status = config_status
                    self.status_time = now
                self._write_record_to_data_server(&#39;status:logger_status&#39;, config_status)

                # Now get and send cruise mode
                mode_map = {&#39;active_mode&#39;: self.api.get_active_mode()}
                self._write_record_to_data_server(&#39;status:cruise_mode&#39;, mode_map)
            except ValueError as e:
                logging.warning(&#39;Error while trying to send logger status: %s&#39;, e)
            time.sleep(self.interval)

    ############################
    def _update_configs_loop(self):
        &#34;&#34;&#34;Iteratively check the API for updated configs and send them to the
        appropriate LoggerRunners.
        &#34;&#34;&#34;
        while not self.quit_flag:
            self._update_configs()
            time.sleep(self.interval)

    ############################
    def _update_configs(self):
        &#34;&#34;&#34;Get list of new (latest) configs. Send to logger supervisor to make
        any necessary changes.

        Note: we can&#39;t fold this into _update_configs_loop() because we may
        need to ask the api to call it independently as a callback when it
        notices that the config has changed. Search for the line:

          api.on_update(callback=logger_manager._update_configs)

        in this file to see where.
        &#34;&#34;&#34;
        # First, grab a status update.
        # self.logger_status = self.supervisor.check_status()
        # self.status_time = time.time()
        with self.config_lock:
            # Get new configs in dict {logger:{&#39;configs&#39;:[config_name,...]}}
            logger_configs = self.api.get_logger_configs()
            if logger_configs:
                supervisor.update_configs(logger_configs)
                self.active_configs = logger_configs

    ############################
    def _send_cruise_definition_loop(self):
        &#34;&#34;&#34;Iteratively assemble information from DB about what loggers should
        exist and what states they *should* be in. We&#39;ll send this to the
        cached data server whenever it changes (or if it&#39;s been a while
        since we have).

        Also, if the logger or config names have changed, signal that we
        need to create a new config file for the supervisord process to
        use.

        Looks like:
          {&#39;active_mode&#39;: &#39;log&#39;,
           &#39;cruise_id&#39;: &#39;NBP1406&#39;,
           &#39;loggers&#39;: {&#39;PCOD&#39;: {&#39;active&#39;: &#39;PCOD-&gt;file/net&#39;,
                                &#39;configs&#39;: [&#39;PCOD-&gt;off&#39;,
                                            &#39;PCOD-&gt;net&#39;,
                                            &#39;PCOD-&gt;file/net&#39;,
                                            &#39;PCOD-&gt;file/net/db&#39;]},
                        next_logger: next_configs,
                        ...
                      },
           &#39;modes&#39;: [&#39;off&#39;, &#39;monitor&#39;, &#39;log&#39;, &#39;log+db&#39;]
          }

        &#34;&#34;&#34;
        last_loaded_timestamp = 0

        while not self.quit_flag:
            try:
                self.cruise = self.api.get_configuration()  # a Cruise object
                if not self.cruise:
                    logging.info(&#39;No cruise definition found in API&#39;)
                    time.sleep(self.interval * 2)
                    continue
                self.cruise_filename = self.cruise.get(&#39;config_filename&#39;, None)
                loaded_time = self.cruise.get(&#39;loaded_time&#39;)
                self.cruise_loaded_time = datetime.datetime.timestamp(loaded_time)

                # Has cruise definition file changed since we loaded it? If so,
                # send a notification to console so it can ask if user wants to
                # reload.
                if self.cruise_filename:
                    try:
                        mtime = os.path.getmtime(self.cruise_filename)
                        if mtime &gt; self.cruise_loaded_time:
                            logging.debug(&#39;Cruise file timestamp changed!&#39;)
                            self._write_record_to_data_server(&#39;status:file_update&#39;, mtime)
                    except FileNotFoundError:
                        logging.debug(&#39;Cruise file &#34;%s&#34; has disappeared?&#39;, self.cruise_filename)

                # Does database have a cruise definition with a newer timestamp?
                # Means user loaded/reloaded definition. Update our maps to
                # reflect the new values and send an updated cruise_definition
                # to the console.
                if self.cruise_loaded_time &gt; last_loaded_timestamp:
                    last_loaded_timestamp = self.cruise_loaded_time
                    logging.info(&#39;New cruise definition detected - rebuilding maps.&#39;)
                    self._load_new_definition_from_api()

            except KeyboardInterrupt:  # (AttributeError, ValueError, TypeError):
                logging.warning(&#39;No cruise definition found in API&#39;)

            # Whether or not we&#39;ve sent an update, sleep
            time.sleep(self.interval * 2)

    ############################
    def _write_record_to_data_server(self, field_name, record):
        &#34;&#34;&#34;Format and label a record and send it to the cached data server.
        &#34;&#34;&#34;
        if self.data_server_writer:
            das_record = DASRecord(fields={field_name: record})
            logging.debug(&#39;DASRecord: %s&#39; % das_record)
            self.data_server_writer.write(das_record)
        else:
            logging.info(&#39;Update: %s: %s&#39;, field_name, record)

################################################################################


def run_data_server(data_server_websocket,
                    data_server_back_seconds, data_server_cleanup_interval,
                    data_server_interval):
    &#34;&#34;&#34;Run a CachedDataServer (to be called as a separate process),
    accepting websocket connections to receive data to be cached and
    served.
    &#34;&#34;&#34;
    # First get the port that we&#39;re going to run the data server on. Because
    # we&#39;re running it locally, it should only have a port, not a hostname.
    # We should try to handle it if they prefix with a &#39;:&#39;, though.
    data_server_websocket = data_server_websocket or DEFAULT_DATA_SERVER_WEBSOCKET
    websocket_port = int(data_server_websocket.split(&#39;:&#39;)[-1])
    server = CachedDataServer(port=websocket_port, interval=data_server_interval)

    # The server will start serving in its own thread after
    # initialization, but we need to manually fire up the cleanup loop
    # if we want it. Maybe we should have this also run automatically in
    # its own thread after initialization?
    server.cleanup_loop()


################################################################################
if __name__ == &#39;__main__&#39;:  # noqa: C901
    import argparse
    import atexit
    import readline

    from server.server_api_command_line import ServerAPICommandLine

    parser = argparse.ArgumentParser()
    parser.add_argument(&#39;--config&#39;, dest=&#39;config&#39;, action=&#39;store&#39;,
                        help=&#39;Name of configuration file to load.&#39;)
    parser.add_argument(&#39;--mode&#39;, dest=&#39;mode&#39;, action=&#39;store&#39;, default=None,
                        help=&#39;Optional name of mode to start system in.&#39;)

    database_choices = [&#39;memory&#39;, &#39;django&#39;]
    if SQLITE_API_DEFINED:
        database_choices.append(&#39;sqlite&#39;)
    parser.add_argument(&#39;--database&#39;, dest=&#39;database&#39;, action=&#39;store&#39;,
                        choices=database_choices,
                        default=&#39;memory&#39;, help=&#39;What backing store database &#39;
                        &#39;to use.&#39;)

    parser.add_argument(&#39;--stderr_file_pattern&#39;, dest=&#39;stderr_file_pattern&#39;,
                        default=&#39;/var/log/openrvdas/{logger}.stderr&#39;,
                        help=&#39;Pattern into which logger name will be &#39;
                        &#39;interpolated to create the file path/name to which &#39;
                        &#39;the logger\&#39;s stderr will be written. E.g. &#39;
                        &#39;\&#39;/var/log/openrvdas/{logger}.stderr\&#39;&#39;)

    # Arguments for cached data server
    parser.add_argument(&#39;--data_server_websocket&#39;, dest=&#39;data_server_websocket&#39;,
                        action=&#39;store&#39;, default=None,
                        help=&#39;Address at which to connect to cached data server &#39;
                        &#39;to send status updates.&#39;)
    parser.add_argument(&#39;--start_data_server&#39;, dest=&#39;start_data_server&#39;,
                        action=&#39;store_true&#39;, default=False,
                        help=&#39;Whether to start our own cached data server.&#39;)
    parser.add_argument(&#39;--data_server_back_seconds&#39;,
                        dest=&#39;data_server_back_seconds&#39;, action=&#39;store&#39;,
                        type=float, default=480,
                        help=&#39;Maximum number of seconds of old data to keep &#39;
                        &#39;for serving to new clients.&#39;)
    parser.add_argument(&#39;--data_server_cleanup_interval&#39;,
                        dest=&#39;data_server_cleanup_interval&#39;,
                        action=&#39;store&#39;, type=float, default=60,
                        help=&#39;How often to clean old data out of the cache.&#39;)
    parser.add_argument(&#39;--data_server_interval&#39;, dest=&#39;data_server_interval&#39;,
                        action=&#39;store&#39;, type=float, default=1,
                        help=&#39;How many seconds to sleep between successive &#39;
                        &#39;sends of data to clients.&#39;)

    parser.add_argument(&#39;--interval&#39;, dest=&#39;interval&#39;, action=&#39;store&#39;,
                        type=float, default=0.5,
                        help=&#39;How many seconds to sleep between logger checks.&#39;)
    parser.add_argument(&#39;--max_tries&#39;, dest=&#39;max_tries&#39;, action=&#39;store&#39;, type=int,
                        default=DEFAULT_MAX_TRIES,
                        help=&#39;Number of times to retry failed loggers.&#39;)

    parser.add_argument(&#39;--no-console&#39;, dest=&#39;no_console&#39;, default=False,
                        action=&#39;store_true&#39;, help=&#39;Run without a console &#39;
                        &#39;that reads commands from stdin.&#39;)

    parser.add_argument(&#39;-v&#39;, &#39;--verbosity&#39;, dest=&#39;verbosity&#39;,
                        default=0, action=&#39;count&#39;,
                        help=&#39;Increase output verbosity&#39;)
    parser.add_argument(&#39;-V&#39;, &#39;--logger_verbosity&#39;, dest=&#39;logger_verbosity&#39;,
                        default=0, action=&#39;count&#39;,
                        help=&#39;Increase output verbosity of component loggers&#39;)
    args = parser.parse_args()

    # Set up logging first of all
    LOG_LEVELS = {0: logging.WARNING, 1: logging.INFO, 2: logging.DEBUG}

    log_level = LOG_LEVELS[min(args.verbosity, max(LOG_LEVELS))]
    logging.basicConfig(format=DEFAULT_LOGGING_FORMAT, level=log_level)

    # What level do we want our component loggers to write?
    logger_log_level = LOG_LEVELS[min(args.logger_verbosity, max(LOG_LEVELS))]

    ############################
    # First off, start any servers we&#39;re supposed to be running
    logging.info(&#39;Preparing to start LoggerManager.&#39;)

    # If we&#39;re supposed to be running our own CachedDataServer, start it
    # here in its own daemon process (daemon so that it dies when we exit).
    if args.start_data_server:
        data_server_proc = multiprocessing.Process(
            name=&#39;openrvdas_data_server&#39;,
            target=run_data_server,
            args=(args.data_server_websocket,
                  args.data_server_back_seconds, args.data_server_cleanup_interval,
                  args.data_server_interval),
            daemon=True)
        data_server_proc.start()

    ############################
    # If we do have a data server, add a handler that will echo all
    # logger_manager stderr output to it
    if args.data_server_websocket:
        stderr_writer = ComposedWriter(
            transforms=ToDASRecordTransform(field_name=&#39;stderr:logger_manager&#39;),
            writers=[CachedDataWriter(data_server=args.data_server_websocket)])
        logging.getLogger().addHandler(StdErrLoggingHandler(stderr_writer,
                                                            parse_to_json=True))

    ############################
    # Instantiate API - a Are we using an in-memory store or Django
    # database as our backing store? Do our imports conditionally, so
    # they don&#39;t actually have to have Django if they&#39;re not using it.
    if args.database == &#39;django&#39;:
        from django_gui.django_server_api import DjangoServerAPI
        api = DjangoServerAPI()
    elif args.database == &#39;memory&#39;:
        from server.in_memory_server_api import InMemoryServerAPI
        api = InMemoryServerAPI()
    elif args.database == &#39;sqlite&#39;:
        from server.sqlite_server_api import SQLiteServerAPI
        api = SQLiteServerAPI()
    else:
        raise ValueError(&#39;Illegal arg for --database: &#34;%s&#34;&#39; % args.database)

    # Now that API is defined, tack on one more logging handler: one
    # that passes messages to API.
    # TODO: decide if we even need this. Disabled for now
    # logging.getLogger().addHandler(WriteToAPILoggingHandler(api))

    ############################
    # Create our logger supervisor.
    supervisor = LoggerSupervisor(
        configs=None,
        stderr_file_pattern=args.stderr_file_pattern,
        stderr_data_server=args.data_server_websocket,
        max_tries=args.max_tries,
        interval=args.interval,
        logger_log_level=logger_log_level)

    ############################
    # Create our LoggerManager
    logger_manager = LoggerManager(
        api=api, supervisor=supervisor,
        data_server_websocket=args.data_server_websocket,
        stderr_file_pattern=args.stderr_file_pattern,
        interval=args.interval,
        log_level=log_level,
        logger_log_level=logger_log_level)

    # When told to quit, shut down gracefully
    api.on_quit(callback=logger_manager.quit)
    api.on_quit(callback=supervisor.quit)

    # When an active config changes in the database, update our configs here
    api.on_update(callback=logger_manager._update_configs)

    # When new configs are loaded, update our file of config processes
    api.on_load(callback=logger_manager._load_new_definition_from_api)

    ############################
    # Start all the various LoggerManager threads running
    logger_manager.start()

    ############################
    # If they&#39;ve given us an initial configuration, get and load it.
    if args.config:
        config = read_config(args.config)

        # Hacky bit: need to stash the config filename for posterity
        if &#39;cruise&#39; in config:
            config[&#39;cruise&#39;][&#39;config_filename&#39;] = args.config
        api.load_configuration(config)

        active_mode = args.mode or api.get_default_mode()
        api.set_active_mode(active_mode)
        api.message_log(source=SOURCE_NAME, user=&#39;(%s@%s)&#39; % (USER, HOSTNAME),
                        log_level=api.INFO,
                        message=&#39;started with: %s, mode %s&#39; %
                        (args.config, active_mode))

    try:
        # If no console, just wait for the configuration update thread to
        # end as a signal that we&#39;re done.
        if args.no_console:
            logging.warning(&#39;--no-console specified; waiting for LoggerManager &#39;
                            &#39;to exit.&#39;)
            if logger_manager.update_configs_thread:
                logger_manager.update_configs_thread.join()
            else:
                logging.warning(&#39;LoggerManager has no update_configs_thread? &#39;
                                &#39;Exiting...&#39;)
        else:
            # Create reader to read/process commands from stdin. Note: this
            # needs to be in main thread for Ctl-C termination to be properly
            # caught and processed, otherwise interrupts go to the wrong places.

            # Set up command line interface to get commands. Start by
            # reading history file, if one exists, to get past commands.
            hist_filename = &#39;.openrvdas_logger_manager_history&#39;
            hist_path = os.path.join(os.path.expanduser(&#39;~&#39;), hist_filename)
            try:
                readline.read_history_file(hist_path)
                # default history len is -1 (infinite), which may grow unruly
                readline.set_history_length(1000)
            except (FileNotFoundError, PermissionError, OSError):
                pass
            atexit.register(readline.write_history_file, hist_path)

            command_line_reader = ServerAPICommandLine(api=api)
            command_line_reader.run()

    except KeyboardInterrupt:
        pass
    logging.debug(&#39;Done with logger_manager.py - exiting&#39;)

    # Ask our SupervisorConnector to shutdown.
    if supervisor:
        supervisor.quit()</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="server.logger_manager.kill_handler"><code class="name flex">
<span>def <span class="ident">kill_handler</span></span>(<span>self, signum)</span>
</code></dt>
<dd>
<div class="desc"><p>Translate an external signal (such as we'd get from os.kill) into a
KeyboardInterrupt, which will signal the start() loop to exit nicely.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def kill_handler(self, signum):
    &#34;&#34;&#34;Translate an external signal (such as we&#39;d get from os.kill) into a
    KeyboardInterrupt, which will signal the start() loop to exit nicely.&#34;&#34;&#34;
    raise KeyboardInterrupt(&#39;Received external kill signal&#39;)</code></pre>
</details>
</dd>
<dt id="server.logger_manager.run_data_server"><code class="name flex">
<span>def <span class="ident">run_data_server</span></span>(<span>data_server_websocket, data_server_back_seconds, data_server_cleanup_interval, data_server_interval)</span>
</code></dt>
<dd>
<div class="desc"><p>Run a CachedDataServer (to be called as a separate process),
accepting websocket connections to receive data to be cached and
served.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def run_data_server(data_server_websocket,
                    data_server_back_seconds, data_server_cleanup_interval,
                    data_server_interval):
    &#34;&#34;&#34;Run a CachedDataServer (to be called as a separate process),
    accepting websocket connections to receive data to be cached and
    served.
    &#34;&#34;&#34;
    # First get the port that we&#39;re going to run the data server on. Because
    # we&#39;re running it locally, it should only have a port, not a hostname.
    # We should try to handle it if they prefix with a &#39;:&#39;, though.
    data_server_websocket = data_server_websocket or DEFAULT_DATA_SERVER_WEBSOCKET
    websocket_port = int(data_server_websocket.split(&#39;:&#39;)[-1])
    server = CachedDataServer(port=websocket_port, interval=data_server_interval)

    # The server will start serving in its own thread after
    # initialization, but we need to manually fire up the cleanup loop
    # if we want it. Maybe we should have this also run automatically in
    # its own thread after initialization?
    server.cleanup_loop()</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="server.logger_manager.LoggerManager"><code class="flex name class">
<span>class <span class="ident">LoggerManager</span></span>
<span>(</span><span>api, supervisor, data_server_websocket=None, stderr_file_pattern='/var/log/openrvdas/{logger}.stderr', interval=0.25, log_level=&lt;function info&gt;, logger_log_level=30)</span>
</code></dt>
<dd>
<div class="desc"><p>Read desired/current logger configs from Django DB and try to run the
loggers specified in those configs.</p>
<pre><code>api - ServerAPI (or subclass) instance by which LoggerManager will get
      its data store updates

supervisor - a LoggerSupervisor object to use to manage logger
      processes.

data_server_websocket - cached data server host:port to which we are
      going to send our status updates.

stderr_file_pattern - Pattern into which logger name will be
      interpolated to create the file path/name to which the
      logger's stderr will be written. E.g.
      '/var/log/openrvdas/{logger}.stderr' If
      data_server_websocket is defined, will write logger
      stderr to it.

interval - number of seconds to sleep between checking/updating loggers

log_level - LoggerManager's log level

logger_log_level - At what logging level our component loggers
      should operate.
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class LoggerManager:
    ############################
    def __init__(self,
                 api, supervisor, data_server_websocket=None,
                 stderr_file_pattern=&#39;/var/log/openrvdas/{logger}.stderr&#39;,
                 interval=0.25, log_level=logging.info, logger_log_level=logging.WARNING):
        &#34;&#34;&#34;Read desired/current logger configs from Django DB and try to run the
        loggers specified in those configs.
        ```
        api - ServerAPI (or subclass) instance by which LoggerManager will get
              its data store updates

        supervisor - a LoggerSupervisor object to use to manage logger
              processes.

        data_server_websocket - cached data server host:port to which we are
              going to send our status updates.

        stderr_file_pattern - Pattern into which logger name will be
              interpolated to create the file path/name to which the
              logger&#39;s stderr will be written. E.g.
              &#39;/var/log/openrvdas/{logger}.stderr&#39; If
              data_server_websocket is defined, will write logger
              stderr to it.

        interval - number of seconds to sleep between checking/updating loggers

        log_level - LoggerManager&#39;s log level

        logger_log_level - At what logging level our component loggers
              should operate.
        ```

        &#34;&#34;&#34;
        # Set signal to catch SIGTERM and convert it into a
        # KeyboardInterrupt so we can shut things down gracefully.
        try:
            signal.signal(signal.SIGTERM, kill_handler)
        except ValueError:
            logging.warning(&#39;LoggerManager not running in main thread; &#39;
                            &#39;shutting down with Ctl-C may not work.&#39;)

        # api class must be subclass of ServerAPI
        if not issubclass(type(api), ServerAPI):
            raise ValueError(&#39;Passed api &#34;%s&#34; must be subclass of ServerAPI&#39; % api)
        self.api = api
        self.supervisor = supervisor

        # Data server to which we&#39;re going to send status updates
        if data_server_websocket:
            self.data_server_writer = CachedDataWriter(data_server_websocket)
        else:
            self.data_server_writer = None

        self.stderr_file_pattern = stderr_file_pattern
        self.interval = interval
        self.logger_log_level = logger_log_level

        # Try to set up logging, right off the bat: reset logging to its
        # freshly-imported state and add handler that also sends logged
        # messages to the cached data server.
        reload(logging)
        logging.basicConfig(format=DEFAULT_LOGGING_FORMAT, level=log_level)

        if self.data_server_writer:
            cds_writer = ComposedWriter(
                transforms=ToDASRecordTransform(data_id=&#39;stderr&#39;,
                                                field_name=&#39;stderr:logger_manager&#39;),
                writers=self.data_server_writer)
            logging.getLogger().addHandler(StdErrLoggingHandler(cds_writer))

        # How our various loops and threads will know it&#39;s time to quit
        self.quit_flag = False

        # Where we store the latest cruise definition and status reports.
        self.cruise = None
        self.cruise_filename = None
        self.cruise_loaded_time = 0

        self.loggers = {}
        self.config_to_logger = {}

        self.logger_status = None
        self.status_time = 0

        # We loop to check the logger status and pass it off to the cached
        # data server. Do this in a separate thread.
        self.check_logger_status_thread = None

        # We&#39;ll loop to check the API for updates to our desired
        # configs. Do this in a separate thread. Also keep track of
        # currently active configs so that we know when an update is
        # actually needed.
        self.update_configs_thread = None
        self.config_lock = threading.Lock()

        self.active_mode = None  # which mode is active now?
        self.active_configs = None  # which configs are active now?

    ############################
    def start(self):
        &#34;&#34;&#34;Start the threads that make up the LoggerManager operation:

        1. Configuration update loop
        2. Loop to read logger stderr/status and either output it or
           transmit it to a cached data server

        Start threads as daemons so that they&#39;ll automatically terminate
        if the main thread does.
        &#34;&#34;&#34;
        logging.info(&#39;Starting LoggerManager&#39;)

        # Check logger status in a separate thread. If we&#39;ve got the
        # address of a data server websocket, send our updates to it.
        self.check_logger_status_loop_thread = threading.Thread(
            name=&#39;check_logger_status_loop&#39;,
            target=self._check_logger_status_loop, daemon=True)
        self.check_logger_status_loop_thread.start()

        # Update configs in a separate thread.
        self.update_configs_thread = threading.Thread(
            name=&#39;update_configs_loop&#39;,
            target=self._update_configs_loop, daemon=True)
        self.update_configs_thread.start()

        # Check logger status in a separate thread. If we&#39;ve got the
        # address of a data server websocket, send our updates to it.
        self.send_cruise_definition_loop_thread = threading.Thread(
            name=&#39;send_cruise_definition_loop&#39;,
            target=self._send_cruise_definition_loop, daemon=True)
        self.send_cruise_definition_loop_thread.start()

    ############################
    def quit(self):
        &#34;&#34;&#34;Exit the loop and shut down all loggers.&#34;&#34;&#34;
        self.quit_flag = True

    ############################
    def _load_new_definition_from_api(self):
        &#34;&#34;&#34;Fetch a new cruise definition from API and build local maps. Then
        send anupdated cruise definition to the console.
        &#34;&#34;&#34;
        logging.info(&#39;Fetching new cruise definitions from API&#39;)
        try:
            with self.config_lock:
                self.loggers = self.api.get_loggers()
                self.config_to_logger = {}
                for logger, logger_configs in self.loggers.items():
                    # Map config_name-&gt;logger
                    for config in self.loggers[logger].get(&#39;configs&#39;, []):
                        self.config_to_logger[config] = logger

                # This is a redundant grab of data when we&#39;re called from
                # _send_cruise_definition_loop(), but we may also be called
                # from a callback when the API alerts us that something has
                # changed. So we need to re-grab self.cruise
                self.cruise = self.api.get_configuration()  # a Cruise object
                self.cruise_filename = self.cruise.get(&#39;config_filename&#39;, None)
                loaded_time = self.cruise.get(&#39;loaded_time&#39;)
                self.cruise_loaded_time = datetime.datetime.timestamp(loaded_time)
                self.active_mode = self.api.get_active_mode()

                # Send updated cruise definition to CDS for console to read.
                cruise_dict = {
                    &#39;cruise_id&#39;: self.cruise.get(&#39;id&#39;, &#39;&#39;),
                    &#39;filename&#39;: self.cruise_filename,
                    &#39;config_timestamp&#39;: self.cruise_loaded_time,
                    &#39;loggers&#39;: self.loggers,
                    &#39;modes&#39;: self.cruise.get(&#39;modes&#39;, {}),
                    &#39;active_mode&#39;: self.active_mode,
                }
                logging.info(&#39;Sending updated cruise definitions to CDS.&#39;)
                self._write_record_to_data_server(
                    &#39;status:cruise_definition&#39;, cruise_dict)
        except (AttributeError, ValueError, TypeError) as e:
            logging.info(&#39;Failed to update cruise definition: %s&#39;, e)

    ############################
    def _check_logger_status_loop(self):
        &#34;&#34;&#34;Grab logger status message from supervisor and send to cached data
        server via websocket. Also send cruise mode as separate message.
        &#34;&#34;&#34;
        while not self.quit_flag:
            now = time.time()
            try:
                config_status = self.supervisor.get_status()
                with self.config_lock:
                    # Stash status, note time and send update
                    self.config_status = config_status
                    self.status_time = now
                self._write_record_to_data_server(&#39;status:logger_status&#39;, config_status)

                # Now get and send cruise mode
                mode_map = {&#39;active_mode&#39;: self.api.get_active_mode()}
                self._write_record_to_data_server(&#39;status:cruise_mode&#39;, mode_map)
            except ValueError as e:
                logging.warning(&#39;Error while trying to send logger status: %s&#39;, e)
            time.sleep(self.interval)

    ############################
    def _update_configs_loop(self):
        &#34;&#34;&#34;Iteratively check the API for updated configs and send them to the
        appropriate LoggerRunners.
        &#34;&#34;&#34;
        while not self.quit_flag:
            self._update_configs()
            time.sleep(self.interval)

    ############################
    def _update_configs(self):
        &#34;&#34;&#34;Get list of new (latest) configs. Send to logger supervisor to make
        any necessary changes.

        Note: we can&#39;t fold this into _update_configs_loop() because we may
        need to ask the api to call it independently as a callback when it
        notices that the config has changed. Search for the line:

          api.on_update(callback=logger_manager._update_configs)

        in this file to see where.
        &#34;&#34;&#34;
        # First, grab a status update.
        # self.logger_status = self.supervisor.check_status()
        # self.status_time = time.time()
        with self.config_lock:
            # Get new configs in dict {logger:{&#39;configs&#39;:[config_name,...]}}
            logger_configs = self.api.get_logger_configs()
            if logger_configs:
                supervisor.update_configs(logger_configs)
                self.active_configs = logger_configs

    ############################
    def _send_cruise_definition_loop(self):
        &#34;&#34;&#34;Iteratively assemble information from DB about what loggers should
        exist and what states they *should* be in. We&#39;ll send this to the
        cached data server whenever it changes (or if it&#39;s been a while
        since we have).

        Also, if the logger or config names have changed, signal that we
        need to create a new config file for the supervisord process to
        use.

        Looks like:
          {&#39;active_mode&#39;: &#39;log&#39;,
           &#39;cruise_id&#39;: &#39;NBP1406&#39;,
           &#39;loggers&#39;: {&#39;PCOD&#39;: {&#39;active&#39;: &#39;PCOD-&gt;file/net&#39;,
                                &#39;configs&#39;: [&#39;PCOD-&gt;off&#39;,
                                            &#39;PCOD-&gt;net&#39;,
                                            &#39;PCOD-&gt;file/net&#39;,
                                            &#39;PCOD-&gt;file/net/db&#39;]},
                        next_logger: next_configs,
                        ...
                      },
           &#39;modes&#39;: [&#39;off&#39;, &#39;monitor&#39;, &#39;log&#39;, &#39;log+db&#39;]
          }

        &#34;&#34;&#34;
        last_loaded_timestamp = 0

        while not self.quit_flag:
            try:
                self.cruise = self.api.get_configuration()  # a Cruise object
                if not self.cruise:
                    logging.info(&#39;No cruise definition found in API&#39;)
                    time.sleep(self.interval * 2)
                    continue
                self.cruise_filename = self.cruise.get(&#39;config_filename&#39;, None)
                loaded_time = self.cruise.get(&#39;loaded_time&#39;)
                self.cruise_loaded_time = datetime.datetime.timestamp(loaded_time)

                # Has cruise definition file changed since we loaded it? If so,
                # send a notification to console so it can ask if user wants to
                # reload.
                if self.cruise_filename:
                    try:
                        mtime = os.path.getmtime(self.cruise_filename)
                        if mtime &gt; self.cruise_loaded_time:
                            logging.debug(&#39;Cruise file timestamp changed!&#39;)
                            self._write_record_to_data_server(&#39;status:file_update&#39;, mtime)
                    except FileNotFoundError:
                        logging.debug(&#39;Cruise file &#34;%s&#34; has disappeared?&#39;, self.cruise_filename)

                # Does database have a cruise definition with a newer timestamp?
                # Means user loaded/reloaded definition. Update our maps to
                # reflect the new values and send an updated cruise_definition
                # to the console.
                if self.cruise_loaded_time &gt; last_loaded_timestamp:
                    last_loaded_timestamp = self.cruise_loaded_time
                    logging.info(&#39;New cruise definition detected - rebuilding maps.&#39;)
                    self._load_new_definition_from_api()

            except KeyboardInterrupt:  # (AttributeError, ValueError, TypeError):
                logging.warning(&#39;No cruise definition found in API&#39;)

            # Whether or not we&#39;ve sent an update, sleep
            time.sleep(self.interval * 2)

    ############################
    def _write_record_to_data_server(self, field_name, record):
        &#34;&#34;&#34;Format and label a record and send it to the cached data server.
        &#34;&#34;&#34;
        if self.data_server_writer:
            das_record = DASRecord(fields={field_name: record})
            logging.debug(&#39;DASRecord: %s&#39; % das_record)
            self.data_server_writer.write(das_record)
        else:
            logging.info(&#39;Update: %s: %s&#39;, field_name, record)</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="server.logger_manager.LoggerManager.quit"><code class="name flex">
<span>def <span class="ident">quit</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Exit the loop and shut down all loggers.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def quit(self):
    &#34;&#34;&#34;Exit the loop and shut down all loggers.&#34;&#34;&#34;
    self.quit_flag = True</code></pre>
</details>
</dd>
<dt id="server.logger_manager.LoggerManager.start"><code class="name flex">
<span>def <span class="ident">start</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Start the threads that make up the LoggerManager operation:</p>
<ol>
<li>Configuration update loop</li>
<li>Loop to read logger stderr/status and either output it or
transmit it to a cached data server</li>
</ol>
<p>Start threads as daemons so that they'll automatically terminate
if the main thread does.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def start(self):
    &#34;&#34;&#34;Start the threads that make up the LoggerManager operation:

    1. Configuration update loop
    2. Loop to read logger stderr/status and either output it or
       transmit it to a cached data server

    Start threads as daemons so that they&#39;ll automatically terminate
    if the main thread does.
    &#34;&#34;&#34;
    logging.info(&#39;Starting LoggerManager&#39;)

    # Check logger status in a separate thread. If we&#39;ve got the
    # address of a data server websocket, send our updates to it.
    self.check_logger_status_loop_thread = threading.Thread(
        name=&#39;check_logger_status_loop&#39;,
        target=self._check_logger_status_loop, daemon=True)
    self.check_logger_status_loop_thread.start()

    # Update configs in a separate thread.
    self.update_configs_thread = threading.Thread(
        name=&#39;update_configs_loop&#39;,
        target=self._update_configs_loop, daemon=True)
    self.update_configs_thread.start()

    # Check logger status in a separate thread. If we&#39;ve got the
    # address of a data server websocket, send our updates to it.
    self.send_cruise_definition_loop_thread = threading.Thread(
        name=&#39;send_cruise_definition_loop&#39;,
        target=self._send_cruise_definition_loop, daemon=True)
    self.send_cruise_definition_loop_thread.start()</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="server" href="index.html">server</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="server.logger_manager.kill_handler" href="#server.logger_manager.kill_handler">kill_handler</a></code></li>
<li><code><a title="server.logger_manager.run_data_server" href="#server.logger_manager.run_data_server">run_data_server</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="server.logger_manager.LoggerManager" href="#server.logger_manager.LoggerManager">LoggerManager</a></code></h4>
<ul class="">
<li><code><a title="server.logger_manager.LoggerManager.quit" href="#server.logger_manager.LoggerManager.quit">quit</a></code></li>
<li><code><a title="server.logger_manager.LoggerManager.start" href="#server.logger_manager.LoggerManager.start">start</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>